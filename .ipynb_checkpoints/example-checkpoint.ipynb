{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import torch_trainer\n",
    "import torch\n",
    "import transformers \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset for spam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):    \n",
    "    \n",
    "    def __init__(self, pd_data, tokenizer =  transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")):\n",
    "        self.df = pd_data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.l = len(self.df.index)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.l\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        utterance = self.df.iloc[[idx]].values.tolist()[0][0]\n",
    "        tag = self.df.iloc[[idx]].values.tolist()[0][1]\n",
    "        utterance = utterance[:20] + utterance[-20:]\n",
    "\n",
    "        tokens = self.tokenizer.tokenize(utterance)\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        \n",
    "        input_tensor = torch.tensor(ids)\n",
    "        target_tensor = torch.tensor(int(tag))\n",
    "        \n",
    "        return input_tensor, target_tensor\n",
    "\n",
    "# for padding zero and generate attention mask\n",
    "def create_mini_batch(samples):\n",
    "        input_tensor = [s[0] for s in samples]\n",
    "        input_tensor = torch.nn.utils.rnn.pad_sequence(input_tensor, batch_first=True)\n",
    "\n",
    "        target_tensor = torch.stack([s[1] for s in samples])\n",
    "\n",
    "        masks_tensors = torch.zeros(input_tensor.shape, dtype=torch.long)\n",
    "        masks_tensors = masks_tensors.masked_fill(input_tensor != 0, 1)\n",
    "\n",
    "        return input_tensor.long(), masks_tensors.long(), target_tensor.long() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models for spam classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spam_classifer1(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, pretrain_model, drop):\n",
    "        super(spam_classifer1, self).__init__()\n",
    "        \n",
    "        self.bert = transformers.BertModel.from_pretrained(pretrain_model)\n",
    "        self.linear = torch.nn.Linear(self.bert.config.hidden_size, 2)\n",
    "        self.dropout = torch.nn.Dropout(p=drop)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "        self.sfmax = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self, input_tensor, masks_tensors, target_tensor):\n",
    "        bert_pool_out = self.bert(input_tensor, attention_mask=masks_tensors).last_hidden_state[:, 0]\n",
    "        droup_out = self.dropout(bert_pool_out)\n",
    "        linear_out = self.linear(droup_out)\n",
    "        s_out = self.sfmax(linear_out)\n",
    "        \n",
    "        if target_tensor != None:\n",
    "            return self.loss_fn(s_out, target_tensor), torch.argmax(s_out, 1)\n",
    "        else:\n",
    "            return torch.argmax(s_out, 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>IsSpam</th>\n",
       "      <th>url_count</th>\n",
       "      <th>email_count</th>\n",
       "      <th>phone_count</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>dunno dat's wat he told me. ok lor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>hey ! don't forget ... you are mine ... for me...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>do u want 2 meet up 2morro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>1000's of girls many local 2 u who r virgins 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>urgent! your mobile number has been awarded wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>i haven't forgotten you, i might have a couple...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>hi. wk been ok - on hols now! yes on for a bit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>a guy who gets used but is too dumb to realize...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>hope youåõre not having too much fun without m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>ìï wait 4 me in sch i finish ard 5..</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4457 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  IsSpam  url_count  \\\n",
       "1819              dunno dat's wat he told me. ok lor...       0          0   \n",
       "5287  hey ! don't forget ... you are mine ... for me...       0          0   \n",
       "4521                         do u want 2 meet up 2morro       0          0   \n",
       "1153  1000's of girls many local 2 u who r virgins 2...       1          0   \n",
       "423   urgent! your mobile number has been awarded wi...       1          0   \n",
       "...                                                 ...     ...        ...   \n",
       "3342  i haven't forgotten you, i might have a couple...       0          0   \n",
       "98    hi. wk been ok - on hols now! yes on for a bit...       0          0   \n",
       "4695  a guy who gets used but is too dumb to realize...       0          0   \n",
       "4068  hope youåõre not having too much fun without m...       0          0   \n",
       "577                ìï wait 4 me in sch i finish ard 5..       0          0   \n",
       "\n",
       "      email_count  phone_count  len  \n",
       "1819            0            0   37  \n",
       "5287            0            0  113  \n",
       "4521            0            0   26  \n",
       "1153            0            0  140  \n",
       "423             0            1  125  \n",
       "...           ...          ...  ...  \n",
       "3342            0            0   91  \n",
       "98              0            0  184  \n",
       "4695            0            0   50  \n",
       "4068            0            0   76  \n",
       "577             0            0   36  \n",
       "\n",
       "[4457 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam = pd.read_csv(\"sms_spam.csv\")\n",
    "train_df, test_df = train_test_split(sms_spam, test_size=0.2)\n",
    "\n",
    "train_ds =  dataset(train_df)\n",
    "test_ds =  dataset(test_df)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set torch trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created folder result\n",
      "will use cuda:0\n",
      "model is setted\n",
      "parameter is setted\n"
     ]
    }
   ],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "trainer = torch_trainer()\n",
    "trainer.set_model_cls(spam_classifer1)\n",
    "trainer.set_model_parameter({\"pretrain_model\":\"bert-base-uncased\", \"drop\":0.3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model ...done\n",
      "Creating dataloader ...done\n",
      "Starting training ...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 1 Train Loss: 0.4504292996207695\n",
      "Epoch: 1 Val Loss: 0.4132642149925232\n",
      "Epoch 1 is current best!!!  test acc: 0.9\n",
      "save model to result/best.pt\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch: 2 Train Loss: 0.4492179697939099\n",
      "Epoch: 2 Val Loss: 0.4132630228996277\n",
      "Epoch 2 is current best!!!  test acc: 0.9\n",
      "save model to result/best.pt\n",
      "--------------------------------------------------------------------------------\n",
      "...Epoch 2 is best!!! acc: 0.9\n"
     ]
    }
   ],
   "source": [
    "trainer.train_find_best_epoch(train_ds, test_ds, batch=20, batch_fn=create_mini_batch, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initaial a model ...done\n",
      "Fold [2, 3, 4, 5] as traing set\n",
      "start training...\n",
      "Epoch: 1 Train Loss: 0.45070363614591247\n",
      "Epoch: 2 Train Loss: 0.44914005569812965\n",
      "... done\n",
      "start testing...done\n",
      "Fold 1 Val Loss: 0.5132624506950378\n",
      "Fold 1 Val Acc: 0.8\n",
      "--------------------------------------------------------------------------------\n",
      "initaial a model ...done\n",
      "Fold [1, 3, 4, 5] as traing set\n",
      "start training...\n",
      "Epoch: 1 Train Loss: 0.45023693044089413\n",
      "Epoch: 2 Train Loss: 0.44921866473595656\n",
      "... done\n",
      "start testing...done\n",
      "Fold 2 Val Loss: 0.5132625102996826\n",
      "Fold 2 Val Acc: 0.8\n",
      "--------------------------------------------------------------------------------\n",
      "initaial a model ...done\n",
      "Fold [1, 2, 4, 5] as traing set\n",
      "start training...\n",
      "Epoch: 1 Train Loss: 0.44996533786769405\n",
      "Epoch: 2 Train Loss: 0.4492179333094524\n",
      "... done\n",
      "start testing...done\n",
      "Fold 3 Val Loss: 0.5132604837417603\n",
      "Fold 3 Val Acc: 0.8\n",
      "--------------------------------------------------------------------------------\n",
      "initaial a model ...done\n",
      "Fold [1, 2, 3, 5] as traing set\n",
      "start training...\n",
      "Epoch: 1 Train Loss: 0.44963009247865376\n",
      "Epoch: 2 Train Loss: 0.4564177801523508\n",
      "... done\n",
      "start testing...done\n",
      "Fold 4 Val Loss: 0.5132644176483154\n",
      "Fold 4 Val Acc: 0.8\n",
      "--------------------------------------------------------------------------------\n",
      "initaial a model ...done\n",
      "Fold [1, 2, 3, 4] as traing set\n",
      "start training...\n",
      "Epoch: 1 Train Loss: 0.4511947369896243\n",
      "Epoch: 2 Train Loss: 0.44926095650335063\n",
      "... done\n",
      "start testing...done\n",
      "Fold 5 Val Loss: 0.5132628083229065\n",
      "Fold 5 Val Acc: 0.8\n",
      "--------------------------------------------------------------------------------\n",
      "Score: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.do_cross_validation(train_ds, k=5, batch=20, batch_fn=create_mini_batch, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
